{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('.venv')",
   "metadata": {
    "interpreter": {
     "hash": "23c4c38a545765ca059e9008eb74cf886e24831d29c80b74baa69019b39b4185"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization.sparsity.keras as sparsity\n",
    "\n",
    "from utils.metrics import count_nonzero_params\n",
    "from prune_model import prune_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 29.4837 - top1: 0.1854 - top3: 0.4601 - val_loss: 6.5115 - val_top1: 0.1991 - val_top3: 0.4741\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 21s 26ms/step - loss: 5.3428 - top1: 0.2247 - top3: 0.5102 - val_loss: 3.9002 - val_top1: 0.2211 - val_top3: 0.5031\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 3.5198 - top1: 0.2441 - top3: 0.5263 - val_loss: 3.2264 - val_top1: 0.2400 - val_top3: 0.5234\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 2.9604 - top1: 0.2524 - top3: 0.5393 - val_loss: 2.9437 - val_top1: 0.2196 - val_top3: 0.4957\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 21s 26ms/step - loss: 2.6982 - top1: 0.2600 - top3: 0.5480 - val_loss: 2.6575 - val_top1: 0.2543 - val_top3: 0.5309\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc0084a3130>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(32, 32, 3)),\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=4),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.TopKCategoricalAccuracy(k=1, name=\"top1\"),\n",
    "        tf.keras.metrics.TopKCategoricalAccuracy(k=3, name=\"top3\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=batch_size,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/juho/Documents/Uni/Semester_6/Bachelorarbeit/Embedded-Systems-Bachelorarbeit/Implementierung/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "initial_sparsity = 0\n",
    "final_sparsity = 0.9\n",
    "start_pruning = 0\n",
    "pruning_steps = 5\n",
    "frequency = 2\n",
    "\n",
    "epochs = start_pruning + pruning_steps * frequency\n",
    "steps_per_epoch = ceil(len(X_train) // batch_size + 1)\n",
    "\n",
    "pruning_schedule = sparsity.PolynomialDecay(\n",
    "    initial_sparsity=initial_sparsity,\n",
    "    final_sparsity=final_sparsity,\n",
    "    begin_step=start_pruning*steps_per_epoch,\n",
    "    end_step=epochs*steps_per_epoch,\n",
    "    frequency=frequency*steps_per_epoch\n",
    ")\n",
    "\n",
    "pruning_model = tf.keras.models.clone_model(\n",
    "    model=model, \n",
    "    clone_function=lambda layer: prune_layer(layer, pruning_schedule)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PruneLowMagnitude --- DepthwiseConv2D\nPruneLowMagnitude --- Flatten\nPruneLowMagnitude --- Dense\n"
     ]
    }
   ],
   "source": [
    "for l1, l2 in zip(pruning_model.layers, model.layers):\n",
    "    print(type(l1).__name__, \"---\", type(l2).__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 22s 27ms/step - loss: 3.0933 - top1: 0.2331 - top3: 0.5179 - val_loss: 2.8012 - val_top1: 0.2383 - val_top3: 0.5183\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 21s 26ms/step - loss: 2.6464 - top1: 0.2578 - top3: 0.5503 - val_loss: 2.6347 - val_top1: 0.2622 - val_top3: 0.5421\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 21s 26ms/step - loss: 2.2361 - top1: 0.2912 - top3: 0.5926 - val_loss: 2.2995 - val_top1: 0.2692 - val_top3: 0.5629\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 21s 26ms/step - loss: 2.1027 - top1: 0.3056 - top3: 0.6095 - val_loss: 2.1635 - val_top1: 0.2737 - val_top3: 0.5766\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 2.0981 - top1: 0.3048 - top3: 0.6082 - val_loss: 2.0884 - val_top1: 0.2981 - val_top3: 0.5963\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 21s 26ms/step - loss: 1.9471 - top1: 0.3297 - top3: 0.6371 - val_loss: 2.2627 - val_top1: 0.2364 - val_top3: 0.5284\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 1.9739 - top1: 0.3214 - top3: 0.6251 - val_loss: 1.9793 - val_top1: 0.3077 - val_top3: 0.6139\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 1.8850 - top1: 0.3484 - top3: 0.6555 - val_loss: 2.0624 - val_top1: 0.2884 - val_top3: 0.5849\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 1.8913 - top1: 0.3424 - top3: 0.6513 - val_loss: 1.9440 - val_top1: 0.3191 - val_top3: 0.6250\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 1.8509 - top1: 0.3617 - top3: 0.6640 - val_loss: 1.9349 - val_top1: 0.3235 - val_top3: 0.6312\n"
     ]
    }
   ],
   "source": [
    "pruning_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.TopKCategoricalAccuracy(k=1, name=\"top1\"),\n",
    "        tf.keras.metrics.TopKCategoricalAccuracy(k=3, name=\"top3\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "pruning_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=[\n",
    "        sparsity.UpdatePruningStep()\n",
    "    ]\n",
    ")\n",
    "\n",
    "pruning_model = sparsity.strip_pruning(pruning_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 0.00%] DepthwiseConv2D\n[ 0.00%] Flatten\n[89.24%] Dense\n"
     ]
    }
   ],
   "source": [
    "for layer in pruning_model.layers:\n",
    "    sparsity = (1 - count_nonzero_params(layer) / layer.count_params()) if layer.count_params() > 0 else 0.0\n",
    "    print(\"[{: >5.2f}%] {}\".format(sparsity * 100, type(layer).__name__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}